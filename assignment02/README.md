# Assignment 2: Pilot UT | DH110 | Kaitlyn Li
## Introduction
![screen shot](oceancare.png)
### About OceanCare
This website showcases OceanCare, an organization focused on marine wildlife protection and restoration. They also partner with international organizations to formulate treaties advocating for the health and protection of oceans and the species home to them. Users can help causes that OceanCare is passionate about by donating funds or becoming a member. The website also serves as a source of information on other involved organizations, different species conservation, and research expeditions.

## Purpose of UT
The purpose of a usability test is to gather feedback from users in order to improve the product itself. For the OceanCare website, conducting a usability test will allow issues with different features and sections of the website to be discovered. Since the user will be talking aloud during the process, it will be interesting to learn about the user's thoughts and how they intuitively navigate through the product. While I went through the OceanCare site, there were three usability issues that stuck out the most to me. 

The usability issues I found with the site were as follows:
| Heuristic Being Tested  | Usability Problem | Task Scenario |
| :------------- | :------------- |:------------- |
| Flexibility and efficiency of use | Forced to find sections of the site through just active scrolling as the search button on top does not work, is not an efficienct way to find information | Finding information about sea turtles |
| User Control and Freedom  | When clicking on the microplastic section, pops up a new tab and have to be forced to click out of it, no back button available | Finding information on microplastics |
| Error Prevention  | Petition seems to be active, yet cannot contribute and is actually completed upon reading, which is very misleading to users as they will spend time trying to find where they can put their signature | Finding an active petition |

## Methodology 

### Setting
This test was conducted inside an apartment room around UCLA, with both the participant and observer seated side by side at the desk. A Macbook Pro laptop was used for the website testing as well as for filling out the survey. I used Zoom to record the video session, including our faces as well as the screen.

### Process of the usability testing
This usability test is intended to be a pilot test, and the procedure used was largely influenced by what was provided in class from Dr. Cho. The survey was created on Google forms using a structure that she outlined that I then personalized to fit this website. The test was overall around 20 minutes long.

Structure of test below:
* Introduction
* Informed Consent
* Background questions
* Pre-test questions
* Three different task scenarios
* Post-test questionnaire
* SUS questions
* Product satisfaction questions
* Demographics

We went through all the aforementioned tasks, with the user providing feedback on her experience. After going through the Demographics section, I stopped the recording and thanked the user for her time.

## Evidence of usability testing
### Survey
Access survey [here.](https://docs.google.com/forms/d/e/1FAIpQLSfECGLg345Jb3b8KbI97tj9ZLg-k0BHa-y3VU9CIqPGT7wNPw/viewform?usp=sf_link)
### Video
Access Video [here.](https://drive.google.com/file/d/1gxn-11y92sGmWa3oEngD2aNs4xJQ70VM/view?usp=sharing) note that only people with a UCLA email can access the video

## Reflection
Overall, this usability testing went smoothly, but improvements could definitely be made. The main issue that happened is that my wifi cut out right before we got to the task section, so I had to pause the recording and then restart it. I could improve this by just finding better wifi connection for next time as UCLA wifi has not been the most reliable these past weeks. Also, the user was a little bit hasty with doing some of the tasks and did not complete them at times, but I did not want to intervene and make her uncomfortable or possibly ask leading questions to influence her actions in any way. I think that next time I need to find a better balance for when I should be speaking up. I guess it was from the pressure of being recorded, as perhaps the user did not want to mess up on camera, but she was also not as exploratory as I expected. For example, the three tasks involved finding some piece of information/section, and I think for at least one of them I should have framed the task as "search for this" rather than "find this" as I expected the faulty search bar to be brought to light but because the user did not attempt to use it, it is not reflected in the video.

I did my best to remain neutral throughout the video, but because I am also inexperienced as a moderator, I realize now I should have probably guided the user a little more throughout the process. Now that I have some experience as a moderator, I know next time to be more thorough with the preparation process. I do think this testing was valuable also in the sense that I gained insight into how a typical user would interact with the site as well as how a user and moderator testing session is coordinated. 
